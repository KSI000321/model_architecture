{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgj4wOsyHhTxpuBfLbAwt1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KSI000321/Legend-13-/blob/main/ResNext_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XBRMzY7dipP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleneckBlock(nn.Module):\n",
        "  # BasicBlock은 논문에서 실험하지 않아 작성 x\n",
        "  expansion = 2 # 기존 ResNet에 비하여(4) 2배로 키움으로써 Bottleneck 문제를 완화\n",
        "\n",
        "  def __init__(self, in_channels, inner_channels, cardinality, stride=1, projection=None):\n",
        "    super().__init__()\n",
        "    self.residual = nn.Sequential(nn.Conv2d(in_channels, inner_channels, 1, bias=False),\n",
        "                                  nn.BatchNorm2d(inner_channels),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Conv2d(inner_channels, inner_channels, 3, stride=stride, padding=1, groups=cardinality, bias=False),\n",
        "                                  # 3x3에만 Grouped Conv 적용\n",
        "                                  nn.BatchNorm2d(inner_channels),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Conv2d(inner_channels, inner_channels * self.expansion, 1, bias=False),\n",
        "                                  nn.BatchNorm2d(inner_channels * self.expansion))\n",
        "    self.projection = projection\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    residual = self.residual(x)\n",
        "\n",
        "    if self.projection is not None:\n",
        "      shortcut = self.projection(x)\n",
        "    else:\n",
        "      shortcut = x\n",
        "\n",
        "    return self.relu(residual + shortcut)\n",
        "\n",
        "class ResNeXt(nn.Module):\n",
        "  def __init__(self, block, num_block_list, cardinality, num_classes = 1000, zero_init_residual = True):\n",
        "    super().__init__()\n",
        "    self.in_channels = 64\n",
        "    self. cardinality = cardinality\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "    self.stage1 = self.make_stage(block, 128, num_block_list[0], stride = 1)\n",
        "    self.stage2 = self.make_stage(block, 256, num_block_list[1], stride = 2)\n",
        "    self.stage3 = self.make_stage(block, 512, num_block_list[2], stride = 2)\n",
        "    self.stage4 = self.make_stage(block, 1024, num_block_list[3], stride = 2)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(1024 * block.expansion, num_classes)\n",
        "\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "\n",
        "    if zero_init_residual:\n",
        "      for m in self.modules():\n",
        "        if isinstance(m, block):\n",
        "          nn.init.constant_(m.residual[-1].weight, 0)\n",
        "\n",
        "\n",
        "\n",
        "  def make_stage(self, block, inner_channels, num_blocks, stride=1):\n",
        "    if stride != 1 or self.in_channels != inner_channels * block.expansion:\n",
        "      projection = nn.Sequential(nn.Conv2d(self.in_channels, inner_channels * block.expansion, 1, stride=stride, bias=False),\n",
        "                                 nn.BatchNorm2d(inner_channels * block.expansion))\n",
        "    else:\n",
        "      projection = None\n",
        "\n",
        "    layers = []\n",
        "    layers += [block(self.in_channels, inner_channels, self.cardinality, stride , projection)]\n",
        "    self.in_channels = inner_channels * block.expansion\n",
        "    for _ in range(1, num_blocks):\n",
        "      layers += [block(self.in_channels, inner_channels, self.cardinality)]\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.stage1(x)\n",
        "    x = self.stage2(x)\n",
        "    x = self.stage3(x)\n",
        "    x = self.stage4(x)\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    out = self.fc(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "uiI8ngRQe3Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnext50(**kwargs):\n",
        "    return ResNeXt(BottleneckBlock, [3, 4, 6, 3], cardinality=32, **kwargs)\n",
        "\n",
        "def resnext101(**kwargs):\n",
        "    return ResNeXt(BottleneckBlock, [3, 4, 23, 3], cardinality=32, **kwargs)"
      ],
      "metadata": {
        "id": "hJhntumSe3Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnext50()\n",
        "# print(model)\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "summary(model, input_size=(2,3,224,224), device='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWb9RxB7e3SY",
        "outputId": "17a04bd0-f35d-4d5e-f5ae-91e6375c702c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNeXt                                  [2, 1000]                 --\n",
              "├─Conv2d: 1-1                            [2, 64, 112, 112]         9,408\n",
              "├─BatchNorm2d: 1-2                       [2, 64, 112, 112]         128\n",
              "├─ReLU: 1-3                              [2, 64, 112, 112]         --\n",
              "├─MaxPool2d: 1-4                         [2, 64, 56, 56]           --\n",
              "├─Sequential: 1-5                        [2, 256, 56, 56]          --\n",
              "│    └─BottleneckBlock: 2-1              [2, 256, 56, 56]          --\n",
              "│    │    └─Sequential: 3-1              [2, 256, 56, 56]          46,592\n",
              "│    │    └─Sequential: 3-2              [2, 256, 56, 56]          16,896\n",
              "│    │    └─ReLU: 3-3                    [2, 256, 56, 56]          --\n",
              "│    └─BottleneckBlock: 2-2              [2, 256, 56, 56]          --\n",
              "│    │    └─Sequential: 3-4              [2, 256, 56, 56]          71,168\n",
              "│    │    └─ReLU: 3-5                    [2, 256, 56, 56]          --\n",
              "│    └─BottleneckBlock: 2-3              [2, 256, 56, 56]          --\n",
              "│    │    └─Sequential: 3-6              [2, 256, 56, 56]          71,168\n",
              "│    │    └─ReLU: 3-7                    [2, 256, 56, 56]          --\n",
              "├─Sequential: 1-6                        [2, 512, 28, 28]          --\n",
              "│    └─BottleneckBlock: 2-4              [2, 512, 28, 28]          --\n",
              "│    │    └─Sequential: 3-8              [2, 512, 28, 28]          217,088\n",
              "│    │    └─Sequential: 3-9              [2, 512, 28, 28]          132,096\n",
              "│    │    └─ReLU: 3-10                   [2, 512, 28, 28]          --\n",
              "│    └─BottleneckBlock: 2-5              [2, 512, 28, 28]          --\n",
              "│    │    └─Sequential: 3-11             [2, 512, 28, 28]          282,624\n",
              "│    │    └─ReLU: 3-12                   [2, 512, 28, 28]          --\n",
              "│    └─BottleneckBlock: 2-6              [2, 512, 28, 28]          --\n",
              "│    │    └─Sequential: 3-13             [2, 512, 28, 28]          282,624\n",
              "│    │    └─ReLU: 3-14                   [2, 512, 28, 28]          --\n",
              "│    └─BottleneckBlock: 2-7              [2, 512, 28, 28]          --\n",
              "│    │    └─Sequential: 3-15             [2, 512, 28, 28]          282,624\n",
              "│    │    └─ReLU: 3-16                   [2, 512, 28, 28]          --\n",
              "├─Sequential: 1-7                        [2, 1024, 14, 14]         --\n",
              "│    └─BottleneckBlock: 2-8              [2, 1024, 14, 14]         --\n",
              "│    │    └─Sequential: 3-17             [2, 1024, 14, 14]         864,256\n",
              "│    │    └─Sequential: 3-18             [2, 1024, 14, 14]         526,336\n",
              "│    │    └─ReLU: 3-19                   [2, 1024, 14, 14]         --\n",
              "│    └─BottleneckBlock: 2-9              [2, 1024, 14, 14]         --\n",
              "│    │    └─Sequential: 3-20             [2, 1024, 14, 14]         1,126,400\n",
              "│    │    └─ReLU: 3-21                   [2, 1024, 14, 14]         --\n",
              "│    └─BottleneckBlock: 2-10             [2, 1024, 14, 14]         --\n",
              "│    │    └─Sequential: 3-22             [2, 1024, 14, 14]         1,126,400\n",
              "│    │    └─ReLU: 3-23                   [2, 1024, 14, 14]         --\n",
              "│    └─BottleneckBlock: 2-11             [2, 1024, 14, 14]         --\n",
              "│    │    └─Sequential: 3-24             [2, 1024, 14, 14]         1,126,400\n",
              "│    │    └─ReLU: 3-25                   [2, 1024, 14, 14]         --\n",
              "│    └─BottleneckBlock: 2-12             [2, 1024, 14, 14]         --\n",
              "│    │    └─Sequential: 3-26             [2, 1024, 14, 14]         1,126,400\n",
              "│    │    └─ReLU: 3-27                   [2, 1024, 14, 14]         --\n",
              "│    └─BottleneckBlock: 2-13             [2, 1024, 14, 14]         --\n",
              "│    │    └─Sequential: 3-28             [2, 1024, 14, 14]         1,126,400\n",
              "│    │    └─ReLU: 3-29                   [2, 1024, 14, 14]         --\n",
              "├─Sequential: 1-8                        [2, 2048, 7, 7]           --\n",
              "│    └─BottleneckBlock: 2-14             [2, 2048, 7, 7]           --\n",
              "│    │    └─Sequential: 3-30             [2, 2048, 7, 7]           3,448,832\n",
              "│    │    └─Sequential: 3-31             [2, 2048, 7, 7]           2,101,248\n",
              "│    │    └─ReLU: 3-32                   [2, 2048, 7, 7]           --\n",
              "│    └─BottleneckBlock: 2-15             [2, 2048, 7, 7]           --\n",
              "│    │    └─Sequential: 3-33             [2, 2048, 7, 7]           4,497,408\n",
              "│    │    └─ReLU: 3-34                   [2, 2048, 7, 7]           --\n",
              "│    └─BottleneckBlock: 2-16             [2, 2048, 7, 7]           --\n",
              "│    │    └─Sequential: 3-35             [2, 2048, 7, 7]           4,497,408\n",
              "│    │    └─ReLU: 3-36                   [2, 2048, 7, 7]           --\n",
              "├─AdaptiveAvgPool2d: 1-9                 [2, 2048, 1, 1]           --\n",
              "├─Linear: 1-10                           [2, 1000]                 2,049,000\n",
              "==========================================================================================\n",
              "Total params: 25,028,904\n",
              "Trainable params: 25,028,904\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 8.46\n",
              "==========================================================================================\n",
              "Input size (MB): 1.20\n",
              "Forward/backward pass size (MB): 460.83\n",
              "Params size (MB): 100.12\n",
              "Estimated Total Size (MB): 562.15\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2, 3, 224, 224)\n",
        "print(model(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQSaYw93e3Wc",
        "outputId": "bf7d2dd7-417b-4c40-e494-3a96bdf7c8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouped conv"
      ],
      "metadata": {
        "id": "xPRGZMyMj5IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nn.Conv2d(128, 256, 3, groups=1).weight.shape)\n",
        "print(nn.Conv2d(128, 256, 3, groups=32).weight.shape)\n",
        "print(nn.Conv2d(128, 256, 3, groups=64).weight.shape)\n",
        "# 필터의 자체 채널 수에만 변화가 있음\n",
        "# 출력 이미지의 채널수에 변화가 있는 것이 아님에 주의"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp_4BQ6_jzt3",
        "outputId": "67ba77db-f0ff-4ff7-fc30-3803adfd14da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 128, 3, 3])\n",
            "torch.Size([256, 4, 3, 3])\n",
            "torch.Size([256, 2, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nn.Conv2d(128, 50, 3, groups=32).weight.shape)\n",
        "# 입력, 출력 사이즈는 무조건 그룹수의 배수이여야함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "5-jKwX7wjzv8",
        "outputId": "6f8260e5-c625-4e68-b632-928a2b759367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "out_channels must be divisible by groups",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-366690fb0c53>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mpadding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mdilation_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             False, _pair(0), groups, bias, padding_mode, **factory_kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'in_channels must be divisible by groups'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out_channels must be divisible by groups'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mvalid_padding_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: out_channels must be divisible by groups"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CfDYUe9Ijzze"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}